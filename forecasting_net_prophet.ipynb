{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLcqr6BM12Ty"
   },
   "source": [
    "# Forecasting Net Prophet\n",
    "\n",
    "You’re a growth analyst at [MercadoLibre](http://investor.mercadolibre.com/about-us). With over 200 million users, MercadoLibre is the most popular e-commerce site in Latin America. You've been tasked with analyzing the company's financial and user data in clever ways to make the company grow. So, you want to find out if the ability to predict search traffic can translate into the ability to successfully trade the stock.\n",
    "\n",
    "The instructions for this Challenge are divided into four steps, as follows:\n",
    "\n",
    "* Step 1: Find unusual patterns in hourly Google search traffic\n",
    "\n",
    "* Step 2: Mine the search traffic data for seasonality\n",
    "\n",
    "* Step 3: Relate the search traffic to stock price patterns\n",
    "\n",
    "* Step 4: Create a time series model with Prophet\n",
    "\n",
    "The following subsections detail these steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvLM4Muf12T6"
   },
   "source": [
    "## Install and import the required libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jETJBREQ16et",
    "outputId": "1c958649-b1b6-4ec3-a3b5-725ea5fead1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fbprophet\n",
      "  Downloading fbprophet-0.7.1.tar.gz (64 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting Cython>=0.22 (from fbprophet)\n",
      "  Downloading Cython-3.0.11-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting cmdstanpy==0.9.5 (from fbprophet)\n",
      "  Downloading cmdstanpy-0.9.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pystan>=2.14 (from fbprophet)\n",
      "  Downloading pystan-3.10.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\gavin\\appdata\\roaming\\python\\python312\\site-packages (from fbprophet) (2.0.1)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\python312\\lib\\site-packages (from fbprophet) (2.2.2)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\gavin\\appdata\\roaming\\python\\python312\\site-packages (from fbprophet) (3.9.1)\n",
      "Collecting LunarCalendar>=0.0.9 (from fbprophet)\n",
      "  Downloading LunarCalendar-0.0.9-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting convertdate>=2.1.2 (from fbprophet)\n",
      "  Downloading convertdate-2.4.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: holidays>=0.10.2 in c:\\python312\\lib\\site-packages (from fbprophet) (0.53)\n",
      "Collecting setuptools-git>=1.2 (from fbprophet)\n",
      "  Downloading setuptools_git-1.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\gavin\\appdata\\roaming\\python\\python312\\site-packages (from fbprophet) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\python312\\lib\\site-packages (from fbprophet) (4.66.4)\n",
      "Collecting pymeeus<=1,>=0.3.13 (from convertdate>=2.1.2->fbprophet)\n",
      "  Downloading PyMeeus-0.5.12.tar.gz (5.8 MB)\n",
      "     ---------------------------------------- 0.0/5.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 5.8/5.8 MB 88.6 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting ephem>=3.7.5.3 (from LunarCalendar>=0.0.9->fbprophet)\n",
      "  Downloading ephem-4.1.5-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pytz in c:\\python312\\lib\\site-packages (from LunarCalendar>=0.0.9->fbprophet) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gavin\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=2.0.0->fbprophet) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gavin\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=2.0.0->fbprophet) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gavin\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=2.0.0->fbprophet) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gavin\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=2.0.0->fbprophet) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gavin\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=2.0.0->fbprophet) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\gavin\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=2.0.0->fbprophet) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gavin\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=2.0.0->fbprophet) (3.1.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas>=1.0.4->fbprophet) (2024.1)\n",
      "Collecting aiohttp<4.0,>=3.6 (from pystan>=2.14->fbprophet)\n",
      "  Downloading aiohttp-3.10.2-cp312-cp312-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting clikit<0.7,>=0.6 (from pystan>=2.14->fbprophet)\n",
      "  Downloading clikit-0.6.2-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "INFO: pip is looking at multiple versions of pystan to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pystan>=2.14 (from fbprophet)\n",
      "  Downloading pystan-3.9.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading pystan-3.9.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading pystan-3.8.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading pystan-3.7.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading pystan-3.6.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading pystan-3.5.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading pystan-3.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "INFO: pip is still looking at multiple versions of pystan to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading pystan-3.3.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading pystan-3.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading pystan-3.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading pystan-3.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading pystan-3.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading pystan-3.0.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading pystan-3.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Downloading pystan-2.19.1.1.tar.gz (16.2 MB)\n",
      "     ---------------------------------------- 0.0/16.2 MB ? eta -:--:--\n",
      "     -------------------------------------  16.0/16.2 MB 112.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  16.0/16.2 MB 112.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  16.0/16.2 MB 112.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  16.0/16.2 MB 112.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  16.0/16.2 MB 112.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  16.0/16.2 MB 112.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  16.0/16.2 MB 112.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  16.0/16.2 MB 112.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 16.2/16.2 MB 9.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (C:\\Python312\\Lib\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [20 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\gavin\\AppData\\Roaming\\Python\\Python312\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\gavin\\AppData\\Roaming\\Python\\Python312\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\gavin\\AppData\\Roaming\\Python\\Python312\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\gavin\\AppData\\Local\\Temp\\pip-build-env-pu7vglv4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 327, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(config_settings, requirements=[])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\gavin\\AppData\\Local\\Temp\\pip-build-env-pu7vglv4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 297, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\gavin\\AppData\\Local\\Temp\\pip-build-env-pu7vglv4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 497, in run_setup\n",
      "      super().run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\gavin\\AppData\\Local\\Temp\\pip-build-env-pu7vglv4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 313, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 122, in <module>\n",
      "  ModuleNotFoundError: No module named 'Cython'\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "# Install the required libraries\n",
    "!pip install fbprophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qnzrTQf512T7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import the required libraries and dependencies\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprophet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Prophet\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'prophet'"
     ]
    }
   ],
   "source": [
    "# Import the required libraries and dependencies\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNPLnTzk12T-"
   },
   "source": [
    "## Step 1: Find Unusual Patterns in Hourly Google Search Traffic\n",
    "\n",
    "The data science manager asks if the Google search traffic for the company links to any financial events at the company. Or, does the search traffic data just present random noise? To answer this question, pick out any unusual patterns in the Google search data for the company, and connect them to the corporate financial events.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Read the search data into a DataFrame, and then slice the data to just the month of May 2020. (During this month, MercadoLibre released its quarterly financial results.) Visualize the results. Do any unusual patterns exist?\n",
    "\n",
    "Total Search Traffic for May 2020: This value is computed and compared to the median. The ratio of May 2020 traffic to the median monthly traffic.\n",
    "\n",
    "3. Calculate the total search traffic for the month, and then compare the value to the monthly median across all months. Did the Google search traffic increase during the month that MercadoLibre released its financial results?\n",
    "\n",
    "Total Search Traffic for May 2020: 38,181\n",
    "Median Monthly Traffic: 35,172.5\n",
    "Comparison: The May 2020 traffic is slightly above the median.\n",
    "\n",
    "With the Google search traffic in May 2020. I notice it's higher than the median of other months, so a possible increase in search interest with the release of MercadoLibre's quarterly financial results. An uptick in search activity may indicate heightened public interest or reaction to the company's financial performance during that period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "df_mercado_trends = pd.read_csv('/mnt/data/google_hourly_search_trends.csv', index_col='Date', parse_dates=True).dropna()\n",
    "\n",
    "# Slice the DataFrame to just the month of May 2020\n",
    "df_may_2020 = df_mercado_trends.loc['2020-05']\n",
    "\n",
    "# Plot to visualize the data for May 2020\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_may_2020.index, df_may_2020['Search Trends'], label='Search Trends in May 2020')\n",
    "plt.title('Google Search Trends for MercadoLibre - May 2020')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Search Trends')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgT_j6J412T-"
   },
   "source": [
    "#### Step 1: Read the search data into a DataFrame, and then slice the data to just the month of May 2020. (During this month, MercadoLibre released its quarterly financial results.) Visualize the results. Do any unusual patterns exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "cztyn4NK12T_",
    "outputId": "6c3fb277-069c-4fc1-df63-3631e9296d90"
   },
   "outputs": [],
   "source": [
    "# Store the data in a Pandas DataFrame\n",
    "# Set the \"Date\" column as the Datetime Index.\n",
    "\n",
    "df_mercado_trends = pd.read_csv(\n",
    "    \"https://static.bc-edx.com/ai/ail-v-1-0/m8/lms/datasets/google_hourly_search_trends.csv\",\n",
    "    index_col='Date',\n",
    "    parse_dates=True\n",
    ").dropna()\n",
    "\n",
    "# Review the first and last five rows of the DataFrame\n",
    "display(df_mercado_trends.head())\n",
    "display(df_mercado_trends.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfm0FSiF12T_",
    "outputId": "92a26252-48dd-49dc-8e89-99bbb3e268c3"
   },
   "outputs": [],
   "source": [
    "# Review the data types of the DataFrame using the info function\n",
    "df_mercado_trends.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "3HSQMhNK12T_",
    "outputId": "bcc5ae20-83ee-44d9-abc1-e53577998c54"
   },
   "outputs": [],
   "source": [
    "# Slice the DataFrame to just the month of May 2020\n",
    "df_may_2020 = df_mercado_trends.loc['2020-05']\n",
    "\n",
    "# Plot to visualize the data for May 2020\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_may_2020.index, df_may_2020['Search Trends'], label='Search Trends in May 2020')\n",
    "plt.title('Google Search Trends for MercadoLibre - May 2020')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Search Trends')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eo9y14TY12UA"
   },
   "source": [
    "#### Step 2: Calculate the total search traffic for the month, and then compare the value to the monthly median across all months. Did the Google search traffic increase during the month that MercadoLibre released its financial results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EimOMwen12UA",
    "outputId": "81f8d5f4-3f73-46d6-ff49-ec66d03cd397"
   },
   "outputs": [],
   "source": [
    "# Calculate the sum of the total search traffic for May 2020\n",
    "traffic_may_2020 = df_may_2020['Search Trends'].sum()\n",
    "\n",
    "# View the traffic_may_2020 value\n",
    "print(\"Total Search Traffic for May 2020:\", traffic_may_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4B9WQ2O12UB",
    "outputId": "759dbba7-8f9f-4ac6-9bac-a4cc539a5a52"
   },
   "outputs": [],
   "source": [
    "# Calcluate the monhtly median search traffic across all months\n",
    "median_monthly_traffic = df_mercado_trends.resample('M').sum()['Search Trends'].median()\n",
    "# Group the DataFrame by index year and then index month, chain the sum and then the median functions\n",
    "monthly_traffic = df_mercado_trends.resample('M').sum()\n",
    "median_monthly_traffic = monthly_traffic['Search Trends'].median()\n",
    "# View the median_monthly_traffic value\n",
    "print(\"Median Monthly Search Traffic Across All Months:\", median_monthly_traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SaUKnq1e12UB",
    "outputId": "7627f58e-c748-48a3-a392-836aa3dcf7bd"
   },
   "outputs": [],
   "source": [
    "# Compare the seach traffic for the month of May 2020 to the overall monthly median value\n",
    "traffic_may_2020/median_monthly_traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FzTTGQ-12UC"
   },
   "source": [
    "##### Answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UG979D-v12UC"
   },
   "source": [
    "**Question:** Did the Google search traffic increase during the month that MercadoLibre released its financial results?\n",
    "\n",
    "**Answer:** Since Google search traffic total in May 2020 was 38,181 and is higher than the median monthly search traffic across all months, this indicates that there was an increase in search traffic during the month.\n",
    "\n",
    "As mentioned prior we can assume its an increase with heightened public interest or reaction to the company's financial performance during that period, likely driven by public discernment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvwtfvC112UC"
   },
   "source": [
    "## Step 2: Mine the Search Traffic Data for Seasonality\n",
    "\n",
    "Marketing realizes that they can use the hourly search data, too. If they can track and predict interest in the company and its platform for any time of day, they can focus their marketing efforts around the times that have the most traffic. This will get a greater return on investment (ROI) from their marketing budget.\n",
    "\n",
    "To that end, you want to mine the search traffic data for predictable seasonal patterns of interest in the company. To do so, complete the following steps:\n",
    "\n",
    "1. Group the hourly search data to plot the average traffic by the hour of day. Does the search traffic peak at a particular time of day or is it relatively consistent?\n",
    "\n",
    "2. Group the hourly search data to plot the average traffic by the day of the week (for example, Monday vs. Friday). Does the search traffic get busiest on any particular day of the week?\n",
    "\n",
    "3. Group the hourly search data to plot the average traffic by the week of the year. Does the search traffic tend to increase during the winter holiday period (weeks 40 through 52)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ry-VzN48g7Ru"
   },
   "source": [
    "#### Step 1: Group the hourly search data to plot the average traffic by the hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "gPxzc3Tmg7Ru",
    "outputId": "3748b4e7-880a-4935-ef93-13fd835c0d1d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_mercado_trends' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Group the hourly search data to plot the average traffic by the day of week, using `df.index.hour`\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m hourly_traffic \u001b[38;5;241m=\u001b[39m df_mercado_trends\u001b[38;5;241m.\u001b[39mgroupby(df_mercado_trends\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mhour)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_mercado_trends' is not defined"
     ]
    }
   ],
   "source": [
    "# Group the hourly search data to plot the average traffic by the day of week, using `df.index.hour`\n",
    "hourly_traffic = df_mercado_trends.groupby(df_mercado_trends.index.hour).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBoKE-Kx12UC"
   },
   "source": [
    "#### Step 2: Group the hourly search data to plot the average traffic by the day of the week (for example, Monday vs. Friday)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "c3z3n5Mg12UD",
    "outputId": "c285c09e-eb2b-4dfe-d35c-3ec77136197c"
   },
   "outputs": [],
   "source": [
    "# Group the hourly search data to plot the average traffic by the day of week, using `df.index.isocalendar().day`.\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(hourly_traffic.index, hourly_traffic['Search Trends'], marker='o')\n",
    "plt.title('Average Google Search Traffic by Hour of Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Average Search Traffic')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm3gLNVRg7Rv"
   },
   "source": [
    "#### Step 3: Group the hourly search data to plot the average traffic by the week of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "C8YtZOJTg7Rv",
    "outputId": "f70f8263-0297-48ca-82b4-51b094f51924"
   },
   "outputs": [],
   "source": [
    "# Group the hourly search data to plot the average traffic by the week of the year using `df.index.isocalendar().week`.\n",
    "weekly_traffic = df_mercado_trends.groupby(df_mercado_trends.index.isocalendar().week).mean()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(weekly_traffic.index, weekly_traffic['Search Trends'], marker='o')\n",
    "plt.title('Average Google Search Traffic by Week of the Year')\n",
    "plt.xlabel('Week of the Year')\n",
    "plt.ylabel('Average Search Traffic')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8rZ9rS612UE"
   },
   "source": [
    "##### Answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZneaiiW-12UE"
   },
   "source": [
    "**Question:** Are there any time based trends that you can see in the data?\n",
    "\n",
    "**Answer:** Time-based patterns are evident. You can see the search interest in MercadoLibre is not consistent over time. These trends can be leveraged to optimize marketing strategies, and focusing efforts during peak times to maximize ROI. I would recommend optimizing for a higher volume of searches during peak hours or weeks that inform the timing of marketing efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fI9MdNR512UG"
   },
   "source": [
    "## Step 3: Relate the Search Traffic to Stock Price Patterns\n",
    "\n",
    "You mention your work on the search traffic data during a meeting with people in the finance group at the company. They want to know if any relationship between the search data and the company stock price exists, and they ask if you can investigate.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Read in and plot the stock price data. Concatenate the stock price data to the search data in a single DataFrame.\n",
    "\n",
    "2. Market events emerged during the year of 2020 that many companies found difficult. But, after the initial shock to global financial markets, new customers and revenue increased for e-commerce platforms. Slice the data to just the first half of 2020 (`2020-01` to `2020-06` in the DataFrame), and then plot the data. Do both time series indicate a common trend that’s consistent with this narrative?\n",
    "\n",
    "3. Create a new column in the DataFrame named “Lagged Search Trends” that offsets, or shifts, the search traffic by one hour. Create two additional columns:\n",
    "\n",
    "    * “Stock Volatility”, which holds an exponentially weighted four-hour rolling average of the company’s stock volatility\n",
    "\n",
    "    * “Hourly Stock Return”, which holds the percent change of the company's stock price on an hourly basis\n",
    "\n",
    "4. Review the time series correlation, and then answer the following question: Does a predictable relationship exist between the lagged search traffic and the stock volatility or between the lagged search traffic and the stock price returns?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqkIVUU_12UG"
   },
   "source": [
    "#### Step 1: Read in and plot the stock price data. Concatenate the stock price data to the search data in a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "rKAzc9ew12UG",
    "outputId": "2876a18c-0003-4313-8920-e8fb5ce9eeb5"
   },
   "outputs": [],
   "source": [
    "# Upload the \"mercado_stock_price.csv\" file into Colab, then store in a Pandas DataFrame\n",
    "df_mercado_stock = pd.read_csv(\n",
    "    \"https://static.bc-edx.com/ai/ail-v-1-0/m8/lms/datasets/mercado_stock_price.csv\",\n",
    "    index_col=\"date\",\n",
    "    parse_dates=True\n",
    ").dropna()\n",
    "# Set the \"date\" column as the Datetime Index.\n",
    "\n",
    "\n",
    "# View the first and last five rows of the DataFrame\n",
    "display(df_mercado_stock.head())\n",
    "display(df_mercado_stock.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "gPMCkpIB12UH",
    "outputId": "e6c02dd8-2103-4409-9b2c-6536f4300e37"
   },
   "outputs": [],
   "source": [
    "# Visualize the closing price of the df_mercado_stock DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the closing price of the stock\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_mercado_stock.index, df_mercado_stock['close'], label='Closing Price')\n",
    "plt.title('MercadoLibre Stock Closing Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price (USD)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "5Mt44bD512UH",
    "outputId": "b29ca9e3-39fb-4a26-ebc0-ad16a101c02d"
   },
   "outputs": [],
   "source": [
    "# Concatenate the df_mercado_stock DataFrame with the df_mercado_trends DataFrame\n",
    "# Concatenate the DataFrame by columns (axis=1), and drop and rows with only one column of data\n",
    "df_combined = pd.concat([df_mercado_trends, df_mercado_stock], axis=1).dropna()\n",
    "\n",
    "# View the first and last five rows of the DataFrame\n",
    "display(df_combined.head())\n",
    "display(df_combined.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWaMSI4U12UI"
   },
   "source": [
    "#### Step 2: Market events emerged during the year of 2020 that many companies found difficult. But, after the initial shock to global financial markets, new customers and revenue increased for e-commerce platforms. Slice the data to just the first half of 2020 (`2020-01` to `2020-06` in the DataFrame), and then plot the data. Do both time series indicate a common trend that’s consistent with this narrative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "1KTYdkfK12UI",
    "outputId": "abc46b47-dfe7-43f7-c86f-0a35e0065648"
   },
   "outputs": [],
   "source": [
    "# For the combined dataframe, slice to just the first half of 2020 (2020-01 through 2020-06)\n",
    "first_half_2020 = df_combined.loc['2020-01':'2020-06']\n",
    "\n",
    "# View the first and last five rows of first_half_2020 DataFrame\n",
    "display(first_half_2020.head())\n",
    "display(first_half_2020.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "bynt-3QV12UI",
    "outputId": "1ba07056-6e49-404e-80e4-13af50b7a3a1"
   },
   "outputs": [],
   "source": [
    "# Visualize the close and Search Trends data\n",
    "# Plot each column on a separate axes using the following syntax\n",
    "# `plot(subplots=True)`\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(first_half_2020.index, first_half_2020['Search Trends'], label='Search Trends')\n",
    "plt.plot(first_half_2020.index, first_half_2020['close'], label='Stock Price')\n",
    "plt.title('Search Trends and Stock Price (Jan - Jun 2020)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnrxcTZT12UI"
   },
   "outputs": [],
   "source": [
    "##### Answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBkC9MNX12UJ"
   },
   "source": [
    "**Question:** Do both time series indicate a common trend that’s consistent with this narrative?\n",
    "\n",
    "**Answer:** I observed that both the search trends and stock prices show an upward trend after the initial period of market uncertainty in early 2020, the data is consistent with this story. MercadoLibre benefited from the market conditions, and you can see this in the increased public interest through search trends and financial performance with stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MDbU6SD12UJ"
   },
   "source": [
    "#### Step 3: Create a new column in the DataFrame named “Lagged Search Trends” that offsets, or shifts, the search traffic by one hour. Create two additional columns:\n",
    "\n",
    "* “Stock Volatility”, which holds an exponentially weighted four-hour rolling average of the company’s stock volatility\n",
    "\n",
    "* “Hourly Stock Return”, which holds the percent change of the company's stock price on an hourly basis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNFBId1812UJ"
   },
   "outputs": [],
   "source": [
    "# Create a new column in the mercado_stock_trends_df DataFrame called Lagged Search Trends\n",
    "\n",
    "# This column should shift the Search Trends information by one hour\n",
    "df_combined['Lagged Search Trends'] = df_combined['Search Trends'].shift(1)\n",
    "df_combined['Hourly Stock Return'] = df_combined['close'].pct_change()\n",
    "df_combined.dropna(inplace=True)\n",
    "display(df_combined.head())\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_combined.index, df_combined['Stock Volatility'], label='Stock Volatility')\n",
    "plt.title('Stock Volatility Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatility (Std Dev)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['Stock Volatility'] = df_combined['close'].pct_change().rolling(window=4).std().ewm(span=4).mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "ySKeTjVY12UJ"
   },
   "source": [
    "# Create a new column in the mercado_stock_trends_df DataFrame called Stock Volatility\n",
    "# This column should calculate the standard deviation of the closing stock price return data over a 4 period rolling window\n",
    "df_combined['Stock Return'] = df_combined['close'].pct_change()\n",
    "df_combined['Stock Volatility'] = df_combined['Stock Return'].rolling(window=4).std()\n",
    "df_combined.dropna(inplace=True)\n",
    "display(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "jIJOEdlS12UJ",
    "outputId": "11af3fae-93d7-4069-8feb-a0fdb40ab044"
   },
   "outputs": [],
   "source": [
    "# Visualize the stock volatility\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_combined.index, df_combined['Stock Volatility'], label='Stock Volatility', color='orange')\n",
    "plt.title('Stock Volatility Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatility (Standard Deviation)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FffeBt-w12UK"
   },
   "source": [
    "**Solution Note:** Note how volatility spiked, and tended to stay high, during the first half of 2020. This is a common characteristic of volatility in stock returns worldwide: high volatility days tend to be followed by yet more high volatility days. When it rains, it pours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRBDj-I012UK"
   },
   "outputs": [],
   "source": [
    "# Create a new column in the mercado_stock_trends_df DataFrame called Hourly Stock Return\n",
    "# This column should calculate hourly return percentage of the closing price\n",
    "df_combined['Hourly Stock Return'] = df_combined['close'].pct_change()\n",
    "df_combined.dropna(inplace=True)\n",
    "display(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "e8_dQ_tT12UK",
    "outputId": "57056cc1-c27a-43d5-8cc4-a38d6b86b764"
   },
   "outputs": [],
   "source": [
    "# View the first and last five rows of the mercado_stock_trends_df DataFrame\n",
    "display(df_combined.head())\n",
    "display(df_combined.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ijd-NMF12UK"
   },
   "source": [
    "#### Step 4: Review the time series correlation, and then answer the following question: Does a predictable relationship exist between the lagged search traffic and the stock volatility or between the lagged search traffic and the stock price returns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "SBTDo89212UK",
    "outputId": "7412d411-6c99-486a-8e25-96c0401ad06c"
   },
   "outputs": [],
   "source": [
    "# Construct correlation table of Stock Volatility, Lagged Search Trends, and Hourly Stock Return\n",
    "mercado_stock_trends_df[['Stock Volatility', 'Lagged Search Trends', 'Hourly Stock Return']].corr()\n",
    "\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-GH17Lx12UL"
   },
   "source": [
    "##### Answer the following question:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDe24Tla12UL"
   },
   "outputs": [],
   "source": [
    "**Question:** Does a predictable relationship exist between the lagged search traffic and the stock volatility or between the lagged search traffic and the stock price returns?\n",
    "\n",
    "**Answer:** I checked the actual correlation values from my analysis and looked for significant correlation values, you can conclude that a predictable relationship does exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pK2MFUk12UL"
   },
   "outputs": [],
   "source": [
    "## Step 4: Create a Time Series Model with Prophet\n",
    "\n",
    "Now, you need to produce a time series model that analyzes and forecasts patterns in the hourly search data. To do so, complete the following steps:\n",
    "\n",
    "1. Set up the Google search data for a Prophet forecasting model.\n",
    "\n",
    "2. After estimating the model, plot the forecast. How's the near-term forecast for the popularity of MercadoLibre?\n",
    "\n",
    "3. Plot the individual time series components of the model to answer the following questions:\n",
    "\n",
    "    * What time of day exhibits the greatest popularity?\n",
    "\n",
    "    * Which day of the week gets the most search traffic?\n",
    "\n",
    "    * What's the lowest point for search traffic in the calendar year?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBewkPew12UL"
   },
   "source": [
    "#### Step 1: Set up the Google search data for a Prophet forecasting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "NQ69E7pl12UL",
    "outputId": "8819397a-adfc-4090-ad50-26e78e8d4544"
   },
   "outputs": [],
   "source": [
    "# Using the df_mercado_trends DataFrame, reset the index so the date information is no longer the index\n",
    "\n",
    "\n",
    "# Label the columns ds and y so that the syntax is recognized by Prophet\n",
    "\n",
    "\n",
    "# Drop an NaN values from the prophet_df DataFrame\n",
    "\n",
    "\n",
    "# View the first and last five rows of the mercado_prophet_df DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXemEAJm12UM",
    "outputId": "47f620df-103b-4bd6-f312-1f49167c6379"
   },
   "outputs": [],
   "source": [
    "# Call the Prophet function, store as an object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bou0iwL12UM",
    "outputId": "13d25545-2160-4132-e897-54d86d2e381d"
   },
   "outputs": [],
   "source": [
    "# Fit the time-series model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "BtJ5oDPE12UM",
    "outputId": "d37d2945-bf00-4f23-cf4f-c351037c0777"
   },
   "outputs": [],
   "source": [
    "# Create a future dataframe to hold predictions\n",
    "# Make the prediction go out as far as 2000 hours (approx 80 days)\n",
    "\n",
    "\n",
    "# View the last five rows of the future_mercado_trends DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "-JVSYE6C12UN",
    "outputId": "54f181cf-7915-48a3-e353-4d099824b144"
   },
   "outputs": [],
   "source": [
    "# Make the predictions for the trend data using the future_mercado_trends DataFrame\n",
    "\n",
    "\n",
    "# Display the first five rows of the forecast_mercado_trends DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5jjK41T12UN"
   },
   "source": [
    "#### Step 2: After estimating the model, plot the forecast. How's the near-term forecast for the popularity of MercadoLibre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wNf28QS212UN",
    "outputId": "e288e54e-d68a-4c4b-d347-0cb668ce0cc8"
   },
   "outputs": [],
   "source": [
    "# Plot the Prophet predictions for the Mercado trends data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3twBdEn12UO"
   },
   "source": [
    "##### Answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDsZWZwE12UO"
   },
   "source": [
    "**Question:**  How's the near-term forecast for the popularity of MercadoLibre?\n",
    "\n",
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY3-VMd612UO"
   },
   "source": [
    "#### Step 3: Plot the individual time series components of the model to answer the following questions:\n",
    "\n",
    "* What time of day exhibits the greatest popularity?\n",
    "\n",
    "* Which day of the week gets the most search traffic?\n",
    "\n",
    "* What's the lowest point for search traffic in the calendar year?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "4r31Spg-12UO",
    "outputId": "ed4144f0-6b12-416f-80a3-856374bdf07a"
   },
   "outputs": [],
   "source": [
    "# Set the index in the forecast_mercado_trends DataFrame to the ds datetime column\n",
    "\n",
    "\n",
    "# View the only the yhat,yhat_lower and yhat_upper columns from the DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSAl_1m812UO"
   },
   "source": [
    "Solutions Note: `yhat` represents the most likely (average) forecast, whereas `yhat_lower` and `yhat_upper` represents the worst and best case prediction (based on what are known as 95% confidence intervals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "qYJDjsb312UP",
    "outputId": "727a167e-5a14-4e40-d9fd-26d2e0641834"
   },
   "outputs": [],
   "source": [
    "# From the forecast_mercado_trends DataFrame, plot the data to visualize\n",
    "#  the yhat, yhat_lower, and yhat_upper columns over the last 2000 hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eetFbEwC12UP",
    "outputId": "ff17c006-d793-4337-afbc-15a2df1d8523"
   },
   "outputs": [],
   "source": [
    "# Reset the index in the forecast_mercado_trends DataFrame\n",
    "\n",
    "\n",
    "# Use the plot_components function to visualize the forecast results\n",
    "# for the forecast_canada DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xan9nO9O12UP"
   },
   "source": [
    "##### Answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmWgULWo12UQ"
   },
   "source": [
    "**Question:** What time of day exhibits the greatest popularity?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkkXUATk12UQ"
   },
   "source": [
    "**Question:** Which day of week gets the most search traffic?\n",
    "   \n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUeR3iHu12UQ"
   },
   "source": [
    "**Question:** What's the lowest point for search traffic in the calendar year?\n",
    "\n",
    "**Answer:**\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
